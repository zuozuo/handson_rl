<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>悬崖漫步环境可视化</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            text-align: center;
            margin: 20px;
            background-color: #f5f5f5;
        }
        h1 {
            color: #333;
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        .algorithm-container {
            margin: 30px 0;
            padding: 20px;
            border: 1px solid #eee;
            border-radius: 8px;
            background-color: #f9f9f9;
        }
        .grid-wrapper {
            display: flex;
            justify-content: center;
            gap: 40px;
            flex-wrap: nowrap;
            margin: 20px auto;
        }
        .grid-container {
            display: grid;
            grid-template-columns: repeat(12, 40px);
            grid-template-rows: repeat(4, 40px);
            gap: 2px;
            margin: 20px auto;
            justify-content: center;
        }
        .cell {
            width: 40px;
            height: 40px;
            border: 1px solid #ccc;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            background-color: #fff;
            font-weight: bold;
        }
        .start {
            background-color: #a8e6cf;
        }
        .goal {
            background-color: #dcedc1;
        }
        .cliff {
            background-color: #ff8b94;
        }
        .state-value {
            position: absolute;
            top: 5px;
            left: 5px;
            font-size: 12px;
            color: #666;
        }
        .value-text {
            font-weight: normal;
            font-size: 14px;
            color: #555;
        }
        .legend {
            display: flex;
            justify-content: center;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        .legend-item {
            display: flex;
            align-items: center;
            margin: 0 10px;
        }
        .legend-color {
            width: 20px;
            height: 20px;
            margin-right: 5px;
            border: 1px solid #ccc;
        }
        .controls {
            margin: 20px 0;
        }
        button {
            padding: 8px 15px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            margin: 0 5px;
        }
        button:hover {
            background-color: #45a049;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #resetBtn {
            background-color: #f44336;
        }
        #resetBtn:hover {
            background-color: #d32f2f;
        }
        .reset-btn {
            background-color: #f44336;
        }
        .reset-btn:hover {
            background-color: #d32f2f;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>悬崖漫步环境可视化</h1>
        
        <div class="legend">
            <div class="legend-item">
                <div class="legend-color start"></div>
                <span>起点</span>
            </div>
            <div class="legend-item">
                <div class="legend-color goal"></div>
                <span>终点</span>
            </div>
            <div class="legend-item">
                <div class="legend-color cliff"></div>
                <span>悬崖</span>
            </div>
        </div>
        
        <div id="algorithmContainers">
            <div id="policyIterationContainer" class="algorithm-container">
                <h2>策略迭代</h2>
                <div id="policyIterationResults" class="results"></div>
                <div class="grid-wrapper">
                    <div>
                        <h3>最优策略</h3>
                        <div class="grid-container" id="policyIterationPolicyGrid"></div>
                    </div>
                    <div>
                        <h3>状态价值</h3>
                        <div class="grid-container" id="policyIterationValueGrid"></div>
                    </div>
                </div>
                <div class="controls">
                    <button id="policyIterationBtn">运行策略迭代</button>
                    <button id="singleStepPolicyBtn">运行一步迭代</button>
                    <button id="resetPolicyIterationBtn" class="reset-btn">重置策略迭代</button>
                </div>
            </div>
            
            <div id="valueIterationContainer" class="algorithm-container">
                <h2>价值迭代</h2>
                <div id="valueIterationResults" class="results"></div>
                <div class="grid-wrapper">
                    <div>
                        <h3>最优策略</h3>
                        <div class="grid-container" id="valueIterationPolicyGrid"></div>
                    </div>
                    <div>
                        <h3>状态价值</h3>
                        <div class="grid-container" id="valueIterationValueGrid"></div>
                    </div>
                </div>
                <div class="controls">
                    <button id="valueIterationBtn">运行价值迭代</button>
                    <button id="singleStepValueBtn">运行一步迭代</button>
                    <button id="resetValueIterationBtn" class="reset-btn">重置价值迭代</button>
                </div>
            </div>
        </div>
    </div>
    
    <script>
        /**
         * 悬崖漫步环境
         */
        class CliffWalkingEnv {
          constructor(ncol = 12, nrow = 4) {
            this.ncol = ncol; // 网格世界的列数
            this.nrow = nrow; // 网格世界的行数
            // 转移矩阵 P[state][action] = [{p, next_state, reward, done}]
            this.P = this.createP();
          }

          /**
           * 创建状态转移矩阵
           */
          createP() {
            // 初始化转移矩阵
            const P = Array(this.nrow * this.ncol).fill().map(() => 
              Array(4).fill().map(() => [])
            );

            // 四种动作: 0-上, 1-下, 2-左, 3-右
            const change = [[0, -1], [0, 1], [-1, 0], [1, 0]];
            
            for (let i = 0; i < this.nrow; i++) {
              for (let j = 0; j < this.ncol; j++) {
                for (let a = 0; a < 4; a++) {
                  const state = i * this.ncol + j;
                  // 判断是否是悬崖或终点
                  if (state === this.nrow * this.ncol - 1) {
                    // 终点
                    P[state][a].push({
                      p: 1.0,
                      next_state: state,
                      reward: 0,
                      done: true
                    });
                    continue;
                  }
                  
                  if (i === this.nrow - 1 && j > 0 && j < this.ncol - 1) {
                    // 悬崖
                    P[state][a].push({
                      p: 1.0,
                      next_state: (this.nrow - 1) * this.ncol,
                      reward: -100,
                      done: true
                    });
                    continue;
                  }
                  
                  // 计算下一个状态
                  let next_i = i + change[a][1];
                  let next_j = j + change[a][0];
                  let reward = -1.0;
                  let done = false;
                  
                  // 边界处理
                  if (next_i < 0 || next_i >= this.nrow || 
                      next_j < 0 || next_j >= this.ncol) {
                    next_i = i;
                    next_j = j;
                  }
                  
                  let next_state = next_i * this.ncol + next_j;
                  
                  // 如果下一个状态是悬崖
                  if (next_i === this.nrow - 1 && next_j > 0 && next_j < this.ncol - 1) {
                    next_state = (this.nrow - 1) * this.ncol;
                    reward = -100;
                    done = true;
                  }
                  
                  // 如果下一个状态是终点
                  if (next_state === this.nrow * this.ncol - 1) {
                    done = true;
                  }
                  
                  P[state][a].push({
                    p: 1.0,
                    next_state: next_state,
                    reward: reward,
                    done: done
                  });
                }
              }
            }
            
            return P;
          }
        }

        /**
         * 策略迭代算法
         */
        class PolicyIteration {
          constructor(env, theta = 1e-5, gamma = 0.9) {
            this.env = env;
            this.theta = theta; // 收敛阈值
            this.gamma = gamma; // 折扣因子
            this.v = Array(env.nrow * env.ncol).fill(0); // 状态价值
            this.pi = Array(env.nrow * env.ncol).fill().map(() => 
              Array(4).fill(0.25)
            ); // 初始策略为均匀随机
            this.policyStable = false; // 策略是否稳定
            this.iterationCount = 0; // 迭代次数
            this.evaluationIterations = []; // 每次策略评估的迭代次数
          }

          /**
           * 策略评估
           */
          policyEvaluation() {
            let iteration = 0;
            while (true) {
              let delta = 0;
              for (let s = 0; s < this.env.nrow * this.env.ncol; s++) {
                let v = this.v[s];
                let new_v = 0;
                
                for (let a = 0; a < 4; a++) {
                  for (const {p, next_state, reward} of this.env.P[s][a]) {
                    new_v += this.pi[s][a] * p * (reward + this.gamma * this.v[next_state]);
                  }
                }
                
                this.v[s] = new_v;
                delta = Math.max(delta, Math.abs(v - new_v));
              }
              
              iteration++;
              
              if (delta < this.theta) {
                return iteration;
              }
              
              // 防止无限循环
              if (iteration > 1000) {
                return iteration;
              }
            }
          }

          /**
           * 策略提升
           */
          policyImprovement() {
            let policy_stable = true;
            
            for (let s = 0; s < this.env.nrow * this.env.ncol; s++) {
              const old_action_probs = [...this.pi[s]];
              
              // 计算Q(s,a)
              const q_sa = Array(4).fill(0);
              
              for (let a = 0; a < 4; a++) {
                for (const {p, next_state, reward} of this.env.P[s][a]) {
                  q_sa[a] += p * (reward + this.gamma * this.v[next_state]);
                }
              }
              
              // 找到最优动作
              const best_a = q_sa.indexOf(Math.max(...q_sa));
              
              // 更新策略为确定性策略
              this.pi[s] = Array(4).fill(0);
              this.pi[s][best_a] = 1.0;
              
              // 检查策略是否稳定
              if (JSON.stringify(old_action_probs) !== JSON.stringify(this.pi[s])) {
                policy_stable = false;
              }
            }
            
            return policy_stable;
          }

          /**
           * 策略迭代
           */
          policyIteration() {
            this.policyStable = false;
            this.iterationCount = 0;
            this.evaluationIterations = [];
            
            while (!this.policyStable) {
              const evalIterations = this.policyEvaluation();
              this.evaluationIterations.push(evalIterations);
              
              this.policyStable = this.policyImprovement();
              this.iterationCount++;
              
              // 防止无限循环
              if (this.iterationCount > 20) {
                break;
              }
            }
            
            return {
              policyIterations: this.iterationCount,
              policyEvaluation: this.evaluationIterations
            };
          }
          
          /**
           * 执行单步策略迭代
           */
          singleStepIteration() {
            if (this.policyStable) {
              return {
                policyIterations: this.iterationCount,
                policyEvaluation: this.evaluationIterations,
                isComplete: true
              };
            }
            
            const evalIterations = this.policyEvaluation();
            this.evaluationIterations.push(evalIterations);
            
            this.policyStable = this.policyImprovement();
            this.iterationCount++;
            
            // 防止无限循环
            if (this.iterationCount > 20) {
              this.policyStable = true;
            }
            
            return {
              policyIterations: this.iterationCount,
              policyEvaluation: this.evaluationIterations,
              isComplete: this.policyStable
            };
          }
        }

        /**
         * 价值迭代算法
         */
        class ValueIteration {
          constructor(env, theta = 1e-5, gamma = 0.9) {
            this.env = env;
            this.theta = theta; // 收敛阈值
            this.gamma = gamma; // 折扣因子
            this.v = Array(env.nrow * env.ncol).fill(0); // 状态价值
            this.pi = Array(env.nrow * env.ncol).fill().map(() => 
              Array(4).fill(0.25)
            ); // 策略
            this.iterationCount = 0; // 迭代次数
            this.isComplete = false; // 是否完成
            this.maxDelta = Infinity; // 最大误差
          }

          /**
           * 价值迭代
           */
          valueIteration() {
            this.iterationCount = 0;
            this.isComplete = false;
            this.maxDelta = Infinity;
            
            while (!this.isComplete) {
              const result = this.singleStepIteration();
              if (result.isComplete) {
                break;
              }
            }
            
            return this.iterationCount;
          }
          
          /**
           * 执行单步价值迭代
           */
          singleStepIteration() {
            if (this.isComplete) {
              return {
                iterationCount: this.iterationCount,
                isComplete: true
              };
            }
            
            let delta = 0;
            this.iterationCount++;
            
            for (let s = 0; s < this.env.nrow * this.env.ncol; s++) {
              const v = this.v[s];
              
              // 计算每个动作的价值
              const q_sa = Array(4).fill(0);
              
              for (let a = 0; a < 4; a++) {
                for (const {p, next_state, reward} of this.env.P[s][a]) {
                  q_sa[a] += p * (reward + this.gamma * this.v[next_state]);
                }
              }
              
              // 更新状态价值为最大的动作价值
              this.v[s] = Math.max(...q_sa);
              
              // 计算最大误差
              delta = Math.max(delta, Math.abs(v - this.v[s]));
            }
            
            this.maxDelta = delta;
            
            // 检查是否收敛
            if (delta < this.theta || this.iterationCount > 1000) {
              this.isComplete = true;
              this.extractPolicy();
            }
            
            return {
              iterationCount: this.iterationCount,
              maxDelta: this.maxDelta,
              isComplete: this.isComplete
            };
          }
          
          /**
           * 从价值函数提取策略
           */
          extractPolicy() {
            for (let s = 0; s < this.env.nrow * this.env.ncol; s++) {
              const q_sa = Array(4).fill(0);
              
              for (let a = 0; a < 4; a++) {
                for (const {p, next_state, reward} of this.env.P[s][a]) {
                  q_sa[a] += p * (reward + this.gamma * this.v[next_state]);
                }
              }
              
              // 找到最优动作
              const best_a = q_sa.indexOf(Math.max(...q_sa));
              
              // 更新策略为确定性策略
              this.pi[s] = Array(4).fill(0);
              this.pi[s][best_a] = 1.0;
            }
          }
        }

        // 初始化环境
        const env = new CliffWalkingEnv();
        const actionMeaning = ['↑', '↓', '←', '→'];
        
        // 悬崖位置和目标位置
        const cliffPos = Array.from({length: 10}, (_, i) => (env.nrow - 1) * env.ncol + i + 1);
        const goalPos = [env.nrow * env.ncol - 1];
        const startPos = (env.nrow - 1) * env.ncol;
        
        // 生成随机策略
        function generateRandomPolicy() {
          // 创建大小为4的数组，表示四个动作的概率
          const policy = Array(4).fill(0);
          
          // 随机选择一个动作赋予100%概率
          const randomAction = Math.floor(Math.random() * 4);
          policy[randomAction] = 1.0;
          
          return policy;
        }
        
        // 创建初始随机策略
        let randomPolicies = Array(env.nrow * env.ncol).fill().map(() => 
          generateRandomPolicy()
        );
        
        // 创建所有网格
        function createAllGrids() {
          createGrid('policyIterationValueGrid');
          createGrid('policyIterationPolicyGrid');
          createGrid('valueIterationValueGrid');
          createGrid('valueIterationPolicyGrid');
        }
        
        // 创建网格
        function createGrid(gridId) {
          const gridContainer = document.getElementById(gridId);
          gridContainer.innerHTML = '';
          
          for (let i = 0; i < env.nrow; i++) {
            for (let j = 0; j < env.ncol; j++) {
              const cell = document.createElement('div');
              cell.className = 'cell';
              
              const state = i * env.ncol + j;
              
              // 设置单元格类型
              if (state === startPos) {
                cell.classList.add('start');
                cell.innerHTML = 'S';
              } else if (state === goalPos[0]) {
                cell.classList.add('goal');
                cell.innerHTML = 'G';
              } else if (cliffPos.includes(state)) {
                cell.classList.add('cliff');
                cell.innerHTML = 'C';
              }
              
              gridContainer.appendChild(cell);
            }
          }
        }
        
        // 显示初始环境状态
        function showInitialState() {
          // 显示所有状态值为0
          showInitialValues('policyIterationValueGrid');
          showInitialValues('valueIterationValueGrid');
          
          // 显示随机策略
          showInitialPolicies('policyIterationPolicyGrid');
          showInitialPolicies('valueIterationPolicyGrid');
          
          // 清空结果区域
          document.getElementById('policyIterationResults').innerHTML = '';
          document.getElementById('valueIterationResults').innerHTML = '';
        }
        
        // 显示初始状态值
        function showInitialValues(gridId) {
          const cells = document.querySelectorAll(`#${gridId} .cell`);
          
          for (let i = 0; i < env.nrow; i++) {
            for (let j = 0; j < env.ncol; j++) {
              const state = i * env.ncol + j;
              const cell = cells[state];
              
              // 显示状态价值
              if (state === startPos) {
                cell.innerHTML = `S<br><span class="value-text">0.00</span>`;
              } else if (state === goalPos[0]) {
                cell.innerHTML = `G<br><span class="value-text">0.00</span>`;
              } else if (cliffPos.includes(state)) {
                cell.innerHTML = `C<br><span class="value-text">0.00</span>`;
              } else {
                cell.innerHTML = `<span class="value-text">0.00</span>`;
              }
            }
          }
        }
        
        // 显示初始随机策略
        function showInitialPolicies(gridId) {
          const cells = document.querySelectorAll(`#${gridId} .cell`);
          
          for (let i = 0; i < env.nrow; i++) {
            for (let j = 0; j < env.ncol; j++) {
              const state = i * env.ncol + j;
              const cell = cells[state];
              
              if (state === startPos) {
                cell.innerHTML = 'S';
              } else if (state === goalPos[0]) {
                cell.innerHTML = 'G';
              } else if (cliffPos.includes(state)) {
                cell.innerHTML = 'C';
              } else {
                // 显示随机策略方向
                const best_a = randomPolicies[state].indexOf(1.0);
                cell.innerHTML = actionMeaning[best_a];
              }
            }
          }
        }
        
        // 更新状态价值网格
        function updateValueGrid(agent, gridId) {
          const cells = document.querySelectorAll(`#${gridId} .cell`);
          
          for (let i = 0; i < env.nrow; i++) {
            for (let j = 0; j < env.ncol; j++) {
              const state = i * env.ncol + j;
              const cell = cells[state];
              
              // 显示状态价值
              const stateValue = agent.v[state].toFixed(2);
              
              // 设置单元格类型和内容
              if (state === startPos) {
                cell.classList.add('start');
                cell.innerHTML = `S<br><span class="value-text">${stateValue}</span>`;
              } else if (state === goalPos[0]) {
                cell.classList.add('goal');
                cell.innerHTML = `G<br><span class="value-text">${stateValue}</span>`;
              } else if (cliffPos.includes(state)) {
                cell.classList.add('cliff');
                cell.innerHTML = `C<br><span class="value-text">${stateValue}</span>`;
              } else {
                cell.innerHTML = `<span class="value-text">${stateValue}</span>`;
              }
            }
          }
        }
        
        // 更新策略网格
        function updatePolicyGrid(agent, gridId) {
          const cells = document.querySelectorAll(`#${gridId} .cell`);
          
          for (let i = 0; i < env.nrow; i++) {
            for (let j = 0; j < env.ncol; j++) {
              const state = i * env.ncol + j;
              const cell = cells[state];
              
              // 设置单元格类型和内容
              if (state === startPos) {
                cell.classList.add('start');
                cell.innerHTML = 'S';
              } else if (state === goalPos[0]) {
                cell.classList.add('goal');
                cell.innerHTML = 'G';
              } else if (cliffPos.includes(state)) {
                cell.classList.add('cliff');
                cell.innerHTML = 'C';
              } else {
                // 找到最优动作
                const best_a = agent.pi[state].indexOf(Math.max(...agent.pi[state]));
                cell.innerHTML = actionMeaning[best_a];
              }
            }
          }
        }
        
        // 重置环境
        function resetEnvironment() {
          // 重新生成随机策略
          randomPolicies = Array(env.nrow * env.ncol).fill().map(() => 
            generateRandomPolicy()
          );
          
          // 显示初始状态
          showInitialState();
        }
        
        // 重置策略迭代环境
        function resetPolicyIteration() {
          // 重新生成随机策略
          randomPolicies = Array(env.nrow * env.ncol).fill().map(() => 
            generateRandomPolicy()
          );
          
          // 重置算法实例
          policyAgent = null;
          
          // 显示初始状态
          showInitialValues('policyIterationValueGrid');
          showInitialPolicies('policyIterationPolicyGrid');
          
          // 清空结果区域
          document.getElementById('policyIterationResults').innerHTML = '';
        }
        
        // 重置价值迭代环境
        function resetValueIteration() {
          // 重新生成随机策略
          randomPolicies = Array(env.nrow * env.ncol).fill().map(() => 
            generateRandomPolicy()
          );
          
          // 重置算法实例
          valueAgent = null;
          
          // 显示初始状态
          showInitialValues('valueIterationValueGrid');
          showInitialPolicies('valueIterationPolicyGrid');
          
          // 清空结果区域
          document.getElementById('valueIterationResults').innerHTML = '';
        }
        
        // 显示结果
        function showResults(algorithmName, agent, iterations) {
          const resultsId = algorithmName === '策略迭代' ? 'policyIterationResults' : 'valueIterationResults';
          const resultsDiv = document.getElementById(resultsId);
          let html = '';
          
          if (algorithmName === '策略迭代') {
            html += `<p>策略迭代次数: ${iterations.policyIterations}</p>`;
            html += `<p>每次策略评估的迭代次数: ${iterations.policyEvaluation.join(', ')}</p>`;
            if (iterations.isComplete) {
              html += `<p>策略已收敛!</p>`;
            }
          } else {
            html += `<p>价值迭代次数: ${iterations.iterationCount}</p>`;
            html += `<p>最大误差: ${iterations.maxDelta?.toFixed(5) || 'N/A'}</p>`;
            if (iterations.isComplete) {
              html += `<p>价值已收敛!</p>`;
            }
          }
          
          resultsDiv.innerHTML = html;
        }
        
        // 全局算法实例
        let policyAgent = null;
        let valueAgent = null;
        
        // 绑定按钮事件
        document.getElementById('policyIterationBtn').addEventListener('click', function() {
          policyAgent = new PolicyIteration(env);
          const iterations = policyAgent.policyIteration();
          updateValueGrid(policyAgent, 'policyIterationValueGrid');
          updatePolicyGrid(policyAgent, 'policyIterationPolicyGrid');
          showResults('策略迭代', policyAgent, iterations);
        });
        
        document.getElementById('valueIterationBtn').addEventListener('click', function() {
          valueAgent = new ValueIteration(env);
          const iterations = valueAgent.valueIteration();
          updateValueGrid(valueAgent, 'valueIterationValueGrid');
          updatePolicyGrid(valueAgent, 'valueIterationPolicyGrid');
          showResults('价值迭代', valueAgent, {iterationCount: iterations});
        });
        
        document.getElementById('singleStepPolicyBtn').addEventListener('click', function() {
          // 如果没有实例，创建一个新的
          if (!policyAgent) {
            policyAgent = new PolicyIteration(env);
          }
          
          // 运行一步迭代
          const iterations = policyAgent.singleStepIteration();
          
          // 更新视图
          updateValueGrid(policyAgent, 'policyIterationValueGrid');
          updatePolicyGrid(policyAgent, 'policyIterationPolicyGrid');
          showResults('策略迭代', policyAgent, iterations);
        });
        
        document.getElementById('singleStepValueBtn').addEventListener('click', function() {
          // 如果没有实例，创建一个新的
          if (!valueAgent) {
            valueAgent = new ValueIteration(env);
          }
          
          // 运行一步迭代
          const iterations = valueAgent.singleStepIteration();
          
          // 更新视图
          updateValueGrid(valueAgent, 'valueIterationValueGrid');
          
          // 如果完成了，更新策略
          if (iterations.isComplete) {
            updatePolicyGrid(valueAgent, 'valueIterationPolicyGrid');
          }
          
          showResults('价值迭代', valueAgent, iterations);
        });
        
        document.getElementById('resetPolicyIterationBtn').addEventListener('click', function() {
          resetPolicyIteration();
        });
        
        document.getElementById('resetValueIterationBtn').addEventListener('click', function() {
          resetValueIteration();
        });
        
        // 初始化所有网格
        createAllGrids();
        
        // 初始显示环境状态
        showInitialState();
    </script>
</body>
</html> 