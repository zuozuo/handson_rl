<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>悬崖漫步环境可视化</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            text-align: center;
            margin: 20px;
            background-color: #f5f5f5;
        }
        h1 {
            color: #333;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        #gridContainer {
            display: flex;
            justify-content: center;
            gap: 40px;
            flex-wrap: wrap;
        }
        .grid-container {
            display: grid;
            grid-template-columns: repeat(12, 50px);
            grid-template-rows: repeat(4, 50px);
            gap: 2px;
            margin: 20px auto;
            justify-content: center;
        }
        .cell {
            width: 50px;
            height: 50px;
            border: 1px solid #ccc;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            background-color: #fff;
            font-weight: bold;
        }
        .start {
            background-color: #a8e6cf;
        }
        .goal {
            background-color: #dcedc1;
        }
        .cliff {
            background-color: #ff8b94;
        }
        .state-value {
            position: absolute;
            top: 5px;
            left: 5px;
            font-size: 12px;
            color: #666;
        }
        .value-text {
            font-weight: normal;
            font-size: 14px;
            color: #555;
        }
        .legend {
            display: flex;
            justify-content: center;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        .legend-item {
            display: flex;
            align-items: center;
            margin: 0 10px;
        }
        .legend-color {
            width: 20px;
            height: 20px;
            margin-right: 5px;
            border: 1px solid #ccc;
        }
        .controls {
            margin: 20px 0;
        }
        button {
            padding: 8px 15px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            margin: 0 5px;
        }
        button:hover {
            background-color: #45a049;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #resetBtn {
            background-color: #f44336;
        }
        #resetBtn:hover {
            background-color: #d32f2f;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>悬崖漫步环境可视化</h1>
        
        <div class="legend">
            <div class="legend-item">
                <div class="legend-color start"></div>
                <span>起点</span>
            </div>
            <div class="legend-item">
                <div class="legend-color goal"></div>
                <span>终点</span>
            </div>
            <div class="legend-item">
                <div class="legend-color cliff"></div>
                <span>悬崖</span>
            </div>
        </div>
        
        <div id="gridContainer">
            <div>
                <h3>状态价值</h3>
                <div class="grid-container" id="valueGrid"></div>
            </div>
            <div>
                <h3>最优策略</h3>
                <div class="grid-container" id="policyGrid"></div>
            </div>
        </div>
        
        <div class="controls">
            <button id="policyIterationBtn">运行策略迭代</button>
            <button id="valueIterationBtn">运行价值迭代</button>
            <button id="resetBtn">重置环境</button>
        </div>
        
        <div id="results"></div>
    </div>
    
    <script>
        /**
         * 悬崖漫步环境
         */
        class CliffWalkingEnv {
          constructor(ncol = 12, nrow = 4) {
            this.ncol = ncol; // 网格世界的列数
            this.nrow = nrow; // 网格世界的行数
            // 转移矩阵 P[state][action] = [{p, next_state, reward, done}]
            this.P = this.createP();
          }

          /**
           * 创建状态转移矩阵
           */
          createP() {
            // 初始化转移矩阵
            const P = Array(this.nrow * this.ncol).fill().map(() => 
              Array(4).fill().map(() => [])
            );

            // 四种动作: 0-上, 1-下, 2-左, 3-右
            const change = [[0, -1], [0, 1], [-1, 0], [1, 0]];
            
            for (let i = 0; i < this.nrow; i++) {
              for (let j = 0; j < this.ncol; j++) {
                for (let a = 0; a < 4; a++) {
                  const state = i * this.ncol + j;
                  // 判断是否是悬崖或终点
                  if (state === this.nrow * this.ncol - 1) {
                    // 终点
                    P[state][a].push({
                      p: 1.0,
                      next_state: state,
                      reward: 0,
                      done: true
                    });
                    continue;
                  }
                  
                  if (i === this.nrow - 1 && j > 0 && j < this.ncol - 1) {
                    // 悬崖
                    P[state][a].push({
                      p: 1.0,
                      next_state: (this.nrow - 1) * this.ncol,
                      reward: -100,
                      done: true
                    });
                    continue;
                  }
                  
                  // 计算下一个状态
                  let next_i = i + change[a][1];
                  let next_j = j + change[a][0];
                  let reward = -1.0;
                  let done = false;
                  
                  // 边界处理
                  if (next_i < 0 || next_i >= this.nrow || 
                      next_j < 0 || next_j >= this.ncol) {
                    next_i = i;
                    next_j = j;
                  }
                  
                  let next_state = next_i * this.ncol + next_j;
                  
                  // 如果下一个状态是悬崖
                  if (next_i === this.nrow - 1 && next_j > 0 && next_j < this.ncol - 1) {
                    next_state = (this.nrow - 1) * this.ncol;
                    reward = -100;
                    done = true;
                  }
                  
                  // 如果下一个状态是终点
                  if (next_state === this.nrow * this.ncol - 1) {
                    done = true;
                  }
                  
                  P[state][a].push({
                    p: 1.0,
                    next_state: next_state,
                    reward: reward,
                    done: done
                  });
                }
              }
            }
            
            return P;
          }
        }

        /**
         * 策略迭代算法
         */
        class PolicyIteration {
          constructor(env, theta = 1e-5, gamma = 0.9) {
            this.env = env;
            this.theta = theta; // 收敛阈值
            this.gamma = gamma; // 折扣因子
            this.v = Array(env.nrow * env.ncol).fill(0); // 状态价值
            this.pi = Array(env.nrow * env.ncol).fill().map(() => 
              Array(4).fill(0.25)
            ); // 初始策略为均匀随机
          }

          /**
           * 策略评估
           */
          policyEvaluation() {
            let iteration = 0;
            while (true) {
              let delta = 0;
              for (let s = 0; s < this.env.nrow * this.env.ncol; s++) {
                let v = this.v[s];
                let new_v = 0;
                
                for (let a = 0; a < 4; a++) {
                  for (const {p, next_state, reward} of this.env.P[s][a]) {
                    new_v += this.pi[s][a] * p * (reward + this.gamma * this.v[next_state]);
                  }
                }
                
                this.v[s] = new_v;
                delta = Math.max(delta, Math.abs(v - new_v));
              }
              
              iteration++;
              
              if (delta < this.theta) {
                return iteration;
              }
              
              // 防止无限循环
              if (iteration > 1000) {
                return iteration;
              }
            }
          }

          /**
           * 策略提升
           */
          policyImprovement() {
            let policy_stable = true;
            
            for (let s = 0; s < this.env.nrow * this.env.ncol; s++) {
              const old_action_probs = [...this.pi[s]];
              
              // 计算Q(s,a)
              const q_sa = Array(4).fill(0);
              
              for (let a = 0; a < 4; a++) {
                for (const {p, next_state, reward} of this.env.P[s][a]) {
                  q_sa[a] += p * (reward + this.gamma * this.v[next_state]);
                }
              }
              
              // 找到最优动作
              const best_a = q_sa.indexOf(Math.max(...q_sa));
              
              // 更新策略为确定性策略
              this.pi[s] = Array(4).fill(0);
              this.pi[s][best_a] = 1.0;
              
              // 检查策略是否稳定
              if (JSON.stringify(old_action_probs) !== JSON.stringify(this.pi[s])) {
                policy_stable = false;
              }
            }
            
            return policy_stable;
          }

          /**
           * 策略迭代
           */
          policyIteration() {
            const iterations = {
              policyEvaluation: [],
              policyIterations: 0
            };
            
            while (true) {
              const evalIterations = this.policyEvaluation();
              iterations.policyEvaluation.push(evalIterations);
              
              const policy_stable = this.policyImprovement();
              iterations.policyIterations++;
              
              if (policy_stable) {
                break;
              }
              
              // 防止无限循环
              if (iterations.policyIterations > 20) {
                break;
              }
            }
            
            return iterations;
          }
        }

        /**
         * 价值迭代算法
         */
        class ValueIteration {
          constructor(env, theta = 1e-5, gamma = 0.9) {
            this.env = env;
            this.theta = theta; // 收敛阈值
            this.gamma = gamma; // 折扣因子
            this.v = Array(env.nrow * env.ncol).fill(0); // 状态价值
            this.pi = Array(env.nrow * env.ncol).fill().map(() => 
              Array(4).fill(0.25)
            ); // 策略
          }

          /**
           * 价值迭代
           */
          valueIteration() {
            let iteration = 0;
            
            while (true) {
              let delta = 0;
              iteration++;
              
              for (let s = 0; s < this.env.nrow * this.env.ncol; s++) {
                const v = this.v[s];
                
                // 计算每个动作的价值
                const q_sa = Array(4).fill(0);
                
                for (let a = 0; a < 4; a++) {
                  for (const {p, next_state, reward} of this.env.P[s][a]) {
                    q_sa[a] += p * (reward + this.gamma * this.v[next_state]);
                  }
                }
                
                // 更新状态价值为最大的动作价值
                this.v[s] = Math.max(...q_sa);
                
                // 计算最大误差
                delta = Math.max(delta, Math.abs(v - this.v[s]));
              }
              
              if (delta < this.theta || iteration > 1000) {
                break;
              }
            }
            
            // 根据价值函数提取最优策略
            for (let s = 0; s < this.env.nrow * this.env.ncol; s++) {
              const q_sa = Array(4).fill(0);
              
              for (let a = 0; a < 4; a++) {
                for (const {p, next_state, reward} of this.env.P[s][a]) {
                  q_sa[a] += p * (reward + this.gamma * this.v[next_state]);
                }
              }
              
              // 找到最优动作
              const best_a = q_sa.indexOf(Math.max(...q_sa));
              
              // 更新策略为确定性策略
              this.pi[s] = Array(4).fill(0);
              this.pi[s][best_a] = 1.0;
            }
            
            return iteration;
          }
        }

        // 初始化环境
        const env = new CliffWalkingEnv();
        const actionMeaning = ['↑', '↓', '←', '→'];
        
        // 悬崖位置和目标位置
        const cliffPos = Array.from({length: 10}, (_, i) => (env.nrow - 1) * env.ncol + i + 1);
        const goalPos = [env.nrow * env.ncol - 1];
        const startPos = (env.nrow - 1) * env.ncol;
        
        // 创建网格
        function createGrid() {
          createValueGrid();
          createPolicyGrid();
        }
        
        // 创建状态价值网格
        function createValueGrid() {
          const gridContainer = document.getElementById('valueGrid');
          gridContainer.innerHTML = '';
          
          for (let i = 0; i < env.nrow; i++) {
            for (let j = 0; j < env.ncol; j++) {
              const cell = document.createElement('div');
              cell.className = 'cell';
              
              const state = i * env.ncol + j;
              
              // 设置单元格类型
              if (state === startPos) {
                cell.classList.add('start');
                cell.innerHTML = 'S';
              } else if (state === goalPos[0]) {
                cell.classList.add('goal');
                cell.innerHTML = 'G';
              } else if (cliffPos.includes(state)) {
                cell.classList.add('cliff');
                cell.innerHTML = 'C';
              }
              
              gridContainer.appendChild(cell);
            }
          }
        }
        
        // 创建策略网格
        function createPolicyGrid() {
          const gridContainer = document.getElementById('policyGrid');
          gridContainer.innerHTML = '';
          
          for (let i = 0; i < env.nrow; i++) {
            for (let j = 0; j < env.ncol; j++) {
              const cell = document.createElement('div');
              cell.className = 'cell';
              
              const state = i * env.ncol + j;
              
              // 设置单元格类型
              if (state === startPos) {
                cell.classList.add('start');
                cell.innerHTML = 'S';
              } else if (state === goalPos[0]) {
                cell.classList.add('goal');
                cell.innerHTML = 'G';
              } else if (cliffPos.includes(state)) {
                cell.classList.add('cliff');
                cell.innerHTML = 'C';
              }
              
              gridContainer.appendChild(cell);
            }
          }
        }
        
        // 更新网格显示状态价值和策略
        function updateGrid(agent) {
          updateValueGrid(agent);
          updatePolicyGrid(agent);
        }
        
        // 更新状态价值网格
        function updateValueGrid(agent) {
          const cells = document.querySelectorAll('#valueGrid .cell');
          
          for (let i = 0; i < env.nrow; i++) {
            for (let j = 0; j < env.ncol; j++) {
              const state = i * env.ncol + j;
              const cell = cells[state];
              
              // 显示状态价值
              const stateValue = agent.v[state].toFixed(2);
              
              // 设置单元格类型和内容
              if (state === startPos) {
                cell.classList.add('start');
                cell.innerHTML = `S<br><span class="value-text">${stateValue}</span>`;
              } else if (state === goalPos[0]) {
                cell.classList.add('goal');
                cell.innerHTML = `G<br><span class="value-text">${stateValue}</span>`;
              } else if (cliffPos.includes(state)) {
                cell.classList.add('cliff');
                cell.innerHTML = `C<br><span class="value-text">${stateValue}</span>`;
              } else {
                cell.innerHTML = `<span class="value-text">${stateValue}</span>`;
              }
            }
          }
        }
        
        // 更新策略网格
        function updatePolicyGrid(agent) {
          const cells = document.querySelectorAll('#policyGrid .cell');
          
          for (let i = 0; i < env.nrow; i++) {
            for (let j = 0; j < env.ncol; j++) {
              const state = i * env.ncol + j;
              const cell = cells[state];
              
              // 设置单元格类型和内容
              if (state === startPos) {
                cell.classList.add('start');
                cell.innerHTML = 'S';
              } else if (state === goalPos[0]) {
                cell.classList.add('goal');
                cell.innerHTML = 'G';
              } else if (cliffPos.includes(state)) {
                cell.classList.add('cliff');
                cell.innerHTML = 'C';
              } else {
                // 找到最优动作
                const best_a = agent.pi[state].indexOf(Math.max(...agent.pi[state]));
                cell.innerHTML = actionMeaning[best_a];
              }
            }
          }
        }
        
        // 显示结果
        function showResults(algorithmName, agent, iterations) {
          const resultsDiv = document.getElementById('results');
          let html = `<h2>${algorithmName}结果</h2>`;
          
          if (algorithmName === '策略迭代') {
            html += `<p>策略迭代次数: ${iterations.policyIterations}</p>`;
            html += `<p>每次策略评估的迭代次数: ${iterations.policyEvaluation.join(', ')}</p>`;
          } else {
            html += `<p>价值迭代次数: ${iterations}</p>`;
          }
          
          resultsDiv.innerHTML = html;
        }
        
        // 重置环境
        function resetEnvironment() {
          // 重新创建网格
          createGrid();
          
          // 清空结果区域
          document.getElementById('results').innerHTML = '';
        }
        
        // 绑定按钮事件
        document.getElementById('policyIterationBtn').addEventListener('click', function() {
          const policyAgent = new PolicyIteration(env);
          const iterations = policyAgent.policyIteration();
          updateGrid(policyAgent);
          showResults('策略迭代', policyAgent, iterations);
        });
        
        document.getElementById('valueIterationBtn').addEventListener('click', function() {
          const valueAgent = new ValueIteration(env);
          const iterations = valueAgent.valueIteration();
          updateGrid(valueAgent);
          showResults('价值迭代', valueAgent, iterations);
        });
        
        document.getElementById('resetBtn').addEventListener('click', function() {
          resetEnvironment();
        });
        
        // 初始绘制网格
        createGrid();
    </script>
</body>
</html> 