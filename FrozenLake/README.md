# FrozenLake 环境动态规划算法实现

## 项目简介

本项目实现了强化学习中的两种基于动态规划的算法来解决FrozenLake问题：
1. 策略迭代算法 (Policy Iteration)
2. 价值迭代算法 (Value Iteration)

FrozenLake环境是一个4x4的网格世界，有以下特性：
- 智能体起始于左上角 (0,0)
- 目标位置在右下角 (3,3)
- 某些格子是"陷阱"，如果智能体踩上去会结束游戏
- 冰面是滑的，所以智能体的动作不一定按预期执行（有滑行的可能性）

## 环境细节

- 滑行概率：
  - 70% 的概率按预期方向移动
  - 10% 的概率向左滑行
  - 10% 的概率向右滑行
  - 10% 的概率向后滑行

- 陷阱位置：(1,1), (1,3), (2,3), (3,0)
- 目标位置：(3,3)
- 奖励：到达目标得到1分，其他情况得到0分

## 算法实现

### 策略迭代 (Policy Iteration)

策略迭代包含两个主要步骤：
1. **策略评估**：计算当前策略下的状态价值函数
2. **策略提升**：基于状态价值函数，使用贪婪策略更新当前策略

重复以上两个步骤，直到策略稳定不变。

### 价值迭代 (Value Iteration)

价值迭代直接利用贝尔曼最优方程计算状态价值：
1. 对每个状态，通过最大化动作价值来更新状态价值
2. 重复此过程直到状态价值收敛
3. 最后根据收敛的状态价值计算最优策略

## 运行方法

```bash
python main.py
```

运行后将显示：
- 环境信息
- 策略迭代算法的结果（状态价值和策略）
- 价值迭代算法的结果（状态价值和策略）

## 文件结构

- `frozen_lake.py`: 实现FrozenLake环境和两种动态规划算法
- `main.py`: 运行程序的主入口

## 参考

本实现基于动手学强化学习教程中的"动态规划算法"一章内容。
参考链接：https://hrl.boyuai.com/chapter/1/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95 